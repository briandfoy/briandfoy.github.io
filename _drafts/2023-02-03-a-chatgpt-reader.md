---
layout: post
title: A ChatGPT reader
categories:
tags:
stopwords:
last_modified:
original_url:
---

ChatGPT is a more efficient way to do what you are already doing: dumbing yourself down and stuffing more shit into the internet. Imagine that weird uncle you don't want to sit next to during the holiday dinner—the one who talks about weird conspiracy theories or the arcane rules of some obscure game. Or, worse yet, the 14-year old who is just discovering what it's like to be, well, anyone, because he read something and wants to tell you what's wrong with everything. Now all of that is automated.

<!--more-->

The excitement over ChatGPT is nothing new, but it's the current manifestation of the blindness of the starry-eyed technological utopianists. The excitement is more realistic for the another sort of person you don't want to be around: the bullshit artist. In one case, the dreamy future is just wrong, but the people pushing it are too inexperienced to know it. The other case, the people are experienced enough to know it's wrong, but that they can use that to fuck you over.

The problem is simple. Computers don't understand anything. They know what we tell them. If we tell a computer that 2 + 2 is 4, then it thinks that is true. But, there are people who tell computers that 2 + 2 is 5, so the computer believes that too.

The entire knowledge of the internet is like that—all the answers that can exist will exist. Look for evidence that the world is round, and you will find that. Look for evidence the world is flat, and you'll find that too. Look for evidence that the world is carried by a giant turtle, and it's there.

But, then, you think, there are people we should trust. Say, like Neil deGrasse Tyson. Are you so sure you should trust him? People who like to check what they read quickly find out that he's a habitual liar. Tyson is effectively the human ChatGPT. He has seen some things, he doesn't check if they are right or wrong, he's not interested if they are right or wrong, and he doesn't care if you think he's a liar. He doesn't care about you at all because he's too busy thinking about himself, so he says whatever he says with the confidence of a person who doesn't care what anyone else thinks. I'm not convinced he does it because he thinks he's right; I'm more likely to believe he does it because he knows he can get away with it even if he gets called out on it.

> Pray, Mr. Babbage, if you put into the machine wrong figures, will the right answers come out?

* https://stratechery.com/2023/from-bing-to-sydney-search-as-distraction-sentient-ai/
* https://simonwillison.net/2023/Feb/15/bing/
* https://fortune.com/2023/02/14/microsoft-chatgpt-bing-unhinged-scared/
* https://www.noemamag.com/deep-learning-alone-isnt-getting-us-to-human-like-ai/
* https://aisnakeoil.substack.com/p/chatgpt-is-a-bullshit-generator-but
* https://mashable.com/article/chatgpt-amazing-wrong
* https://www.vice.com/en/article/wxnaem/stack-overflow-bans-chatgpt-for-constantly-giving-wrong-answers
* https://www.washingtonpost.com/business/beware-chatgpt-trying-to-teach-your-kids-math-or-anything/2023/02/01/951af654-a1f1-11ed-8b47-9863fda8e494_story.html
* https://www.poynter.org/ifcn/2023/could-chatgpt-supercharge-false-narratives/
* https://www.theatlantic.com/technology/archive/2023/02/chatgpt-ai-detector-machine-learning-technology-bureaucracy/672927/?utm_source=feed
* https://www.scotusblog.com/2023/01/no-ruth-bader-ginsburg-did-not-dissent-in-obergefell-and-other-things-chatgpt-gets-wrong-about-the-supreme-court/
* https://theconversation.com/chatgpt-is-great-youre-just-using-it-wrong-198848
* https://moz.com/blog/chatgpt-steered-me-wrong
* https://www.aljazeera.com/economy/2023/2/8/google-shares-tank-8-as-ai-chatbot-bard-flubs-answer-in-ad
* https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web
* https://www.youtube.com/watch?v=IgxzcOugvEI
* https://dkb.blog/p/bing-ai-cant-be-trusted
* https://www.theatlantic.com/technology/archive/2022/12/chatgpt-openai-artificial-intelligence-writing-ethics/672386/
* https://nymag.com/intelligencer/article/ai-artificial-intelligence-chatbots-emily-m-bender.html
* https://www.theatlantic.com/ideas/archive/2023/07/godel-escher-bach-geb-ai/674589/?utm_source=feed
* https://www.washingtonpost.com/technology/2023/07/08/gizmodo-ai-errors-star-wars/
* https://reason.com/volokh/2023/07/13/new-lawsuit-against-bing-based-on-allegedly-ai-hallucinated-libelous-statements/

##

* https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web

> Obviously, no one can speak for all writers, but let me make the argument that starting with a blurry copy of unoriginal work isn’t a good way to create original work. If you’re a writer, you will write a lot of unoriginal work before you write something original. And the time and effort expended on that unoriginal work isn’t wasted; on the contrary, I would suggest that it is precisely what enables you to eventually create something original.

## Notes

> Shakespeare didn't have a word processor. When we got word processors we didn't get shakespeares. We got to separate the two out. There's creativity, there's technology. They're interrelated. But technology is not necessarily creative.

Harrison Ellenshaw - Associate Producer/Visual Effects Supervisor - TRON

<iframe width="560" height="315" src="https://www.youtube.com/embed/wSiEklGobmY" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
